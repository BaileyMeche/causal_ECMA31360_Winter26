---
title: "ECMA 31360, PSet 2: Solutions"
author: "YOUR NAMES, University of Chicago"
geometry: "left=1cm,right=1cm,top=1cm,bottom=1.5cm"
date: "XX-XX-2026"
output: pdf_document
header-includes:
  - \usepackage{caption}
  - \usepackage{float}
  - \usepackage{xcolor}
  - \usepackage{amsmath}
  - \usepackage{enumitem}
---

```{r setup-repos, include=FALSE}
# Ensure CRAN is set for non-interactive knit sessions
options(repos = c(CRAN = "https://cloud.r-project.org"))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = "H", out.extra = "")
```


# Carry-over from PSet2 

<!-- Insert here any script from PSet2 that you need for PSet3 -->

---

# (\textcolor{blue}{[ \ \ ]} out of 50p) PART I: Test Balance in the Observed Predetermined Variables (OPVs)

## (\textcolor{blue}{[ \ \ ]} out of 15p) Q1: Read and Understand the NSW Application's Companion Document

Done!

---

## (\textcolor{blue}{[ \ \ ]} out of 23p) Q2: Implement Procedure 4 (SUR Estimation followed by Joint Testing)

### (\textcolor{blue}{[ \ \ ]} out of 10p) Q2.a: SUR Estimation
```{r}
# Load packages
library(systemfit)

# Load data and create treatment indicator
treated <- read.csv("nswre74_treated.csv")
control <- read.csv("nswre74_control.csv")
treated$treat <- 1
control$treat <- 0
df <- rbind(treated, control)

# OPVs
opvs <- c("age","edu","nodegree","black","hisp",
          "married","u74","u75","re74","re75")

# SUR system: one equation per OPV
sur_system <- setNames(
  lapply(opvs, function(v) as.formula(paste(v, "~ treat"))),
  opvs
)

# Estimate SUR (FGLS)
sur_fit <- systemfit(sur_system, data = df, method = "SUR")

summary(sur_fit)

```


### Script and Output
We estimate a 10-equation SUR system where each OPV is regressed on the treatment indicator.
The intercept in each equation equals the control-group mean of that OPV, and the coefficient on treat equals the treated–control difference in means.
The estimated residual covariance/correlation matrices show substantial cross-equation dependence for economically related OPVs (e.g., u74–u75, re74–re75, edu–nodegree), which motivates using SUR and is required for the joint balance test in subsequent questions.

---

### (\textcolor{blue}{[ \ \ ]} out of 1p) Q2.b: Compare FGLS to OLS equation-by-equation
```{r}
# Q2.b: OLS equation-by-equation (for comparison)
ols_fits <- lapply(opvs, function(v) lm(as.formula(paste0(v, " ~ treat")), data = df))
names(ols_fits) <- opvs

# Compare treat coefficients
sapply(ols_fits, function(m) coef(m)["treat"])
coef(sur_fit)[grep("treat", names(coef(sur_fit)))]

```
Since each equation has the same regressors (an intercept term and a common treatment indicator), the point estimates from SUR/FGLS are the same as those from OLS for each equation (i.e., the estimated mean differences between the treatment and control groups are the same). The key advantage of SUR is that it can estimate the full cross-equation variance-covariance structure, which is necessary for conducting joint balance tests across different OPVs (and may lead to different systematic standard errors for linear combinations of the coefficients).
---

### (\textcolor{blue}{[ \ \ ]} out of 3p) Q2.c: Take a closer look at the variance-covariance matrix

### Script and Output
```{r q2c-verify, echo=TRUE}
V_hat <- vcov(sur_fit)
nm <- names(coef(sur_fit))
nm[1:4]  # should look like: age_(Intercept), age_treat, edu_(Intercept), edu_treat

i01 <- 1  # pi0,1
i11 <- 2  # pi1,1
i02 <- 3  # pi0,2
i12 <- 4  # pi1,2

# (i) should be ~ 0
V_hat[i01, i11] + V_hat[i01, i01]

# (ii) should be ~ 0
V_hat[i01, i12] + V_hat[i01, i02]

# (iii) should be ~ 0
V_hat[i01, i12] - V_hat[i11, i02]

```
We estimate, for each OPV $j=1,\ldots,10$, the regression
\[
X_{ij} = \pi_{0,j} + \pi_{1,j} D_i + u_{ij},
\]
where $D_i \in \{0,1\}$ is the treatment indicator. Because the regressor is only an intercept and a binary variable, the OLS (and hence the equation-by-equation component of the SUR estimator) admits a simple "group-mean" representation:
\[
\widehat{\pi}_{0,j} = \bar X_{j,0}, 
\qquad
\widehat{\pi}_{1,j} = \bar X_{j,1} - \bar X_{j,0},
\]
where
\[
\bar X_{j,0} := \frac{1}{n_0}\sum_{i:D_i=0} X_{ij},
\qquad
\bar X_{j,1} := \frac{1}{n_1}\sum_{i:D_i=1} X_{ij}.
\]
Thus, $\widehat{\pi}_{0,j}$ is the control-group mean of OPV $j$, and $\widehat{\pi}_{1,j}$ is the treated--control difference in means for OPV $j$.

Expression (1) is the top-left $4\times 4$ block of $\widehat{\mathrm{Var}}(\widehat{\pi})$ for the parameter vector
\[
(\widehat{\pi}_{0,1},\widehat{\pi}_{1,1},\widehat{\pi}_{0,2},\widehat{\pi}_{1,2})'.
\]
The following equalities follow directly from the above identities and the (approximate) independence between the treated and control subsamples implied by unconditional random assignment (URA).

\paragraph{(i) Why is $\widehat{\mathrm{Cov}}[\widehat{\pi}_{0,1},\widehat{\pi}_{1,1}] = -\widehat{\mathrm{Var}}[\widehat{\pi}_{0,1}]$?}
Using $\widehat{\pi}_{0,1}=\bar X_{1,0}$ and $\widehat{\pi}_{1,1}=\bar X_{1,1}-\bar X_{1,0}$,
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{0,1},\widehat{\pi}_{1,1})
= \widehat{\mathrm{Cov}}\!\left(\bar X_{1,0},\,\bar X_{1,1}-\bar X_{1,0}\right)
= \widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{1,1}) - \widehat{\mathrm{Var}}(\bar X_{1,0}).
\]
Under URA, $\bar X_{1,0}$ and $\bar X_{1,1}$ are based on non-overlapping subsamples and are approximately independent, hence
$\widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{1,1}) \approx 0$.
Therefore,
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{0,1},\widehat{\pi}_{1,1})
= -\widehat{\mathrm{Var}}(\bar X_{1,0})
= -\widehat{\mathrm{Var}}(\widehat{\pi}_{0,1}).
\]

\paragraph{(ii) Why is $\widehat{\mathrm{Cov}}[\widehat{\pi}_{0,1},\widehat{\pi}_{1,2}] = -\widehat{\mathrm{Cov}}[\widehat{\pi}_{0,1},\widehat{\pi}_{0,2}]$?}
Using $\widehat{\pi}_{0,1}=\bar X_{1,0}$ and $\widehat{\pi}_{1,2}=\bar X_{2,1}-\bar X_{2,0}$,
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{0,1},\widehat{\pi}_{1,2})
= \widehat{\mathrm{Cov}}\!\left(\bar X_{1,0},\,\bar X_{2,1}-\bar X_{2,0}\right)
= \widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{2,1}) - \widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{2,0}).
\]
Again, URA implies $\widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{2,1}) \approx 0$, so
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{0,1},\widehat{\pi}_{1,2})
= -\widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{2,0})
= -\widehat{\mathrm{Cov}}(\widehat{\pi}_{0,1},\widehat{\pi}_{0,2}),
\]
since $\widehat{\pi}_{0,2}=\bar X_{2,0}$.

\paragraph{(iii) Why is $\widehat{\mathrm{Cov}}[\widehat{\pi}_{0,1},\widehat{\pi}_{1,2}] = \widehat{\mathrm{Cov}}[\widehat{\pi}_{1,1},\widehat{\pi}_{0,2}]$?}
Compute
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{1,1},\widehat{\pi}_{0,2})
= \widehat{\mathrm{Cov}}\!\left(\bar X_{1,1}-\bar X_{1,0},\,\bar X_{2,0}\right)
= \widehat{\mathrm{Cov}}(\bar X_{1,1},\bar X_{2,0}) - \widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{2,0}).
\]
Under URA, $\widehat{\mathrm{Cov}}(\bar X_{1,1},\bar X_{2,0}) \approx 0$, hence
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{1,1},\widehat{\pi}_{0,2})
= -\widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{2,0}).
\]
But part (ii) showed
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{0,1},\widehat{\pi}_{1,2})
= -\widehat{\mathrm{Cov}}(\bar X_{1,0},\bar X_{2,0}),
\]
so
\[
\widehat{\mathrm{Cov}}(\widehat{\pi}_{0,1},\widehat{\pi}_{1,2})
= \widehat{\mathrm{Cov}}(\widehat{\pi}_{1,1},\widehat{\pi}_{0,2}).
\]

### Commentary
Because each equation includes only an intercept and a binary treatment indicator,
$\widehat{\pi}_{0,j}$ equals the control-group mean and
$\widehat{\pi}_{1,j}$ equals the treated--control difference in means.
Under unconditional random assignment, treated and control subsamples are (approximately)
independent.
These two facts jointly imply the sign and symmetry restrictions in the top-left
$4\times 4$ block of $\widehat{\mathrm{Var}}(\widehat{\pi})$, and the implied equalities
are verified numerically up to machine precision.

---

### (\textcolor{blue}{[ \ \ ]} out of 4p) Q2.d: Implement Joint Test Manually
```{r}
# coef and vcov from SUR
b_hat <- coef(sur_fit)
V_hat <- vcov(sur_fit)
nm <- names(b_hat)

# 1) pick the J=10 treat coefficients
treat_idx <- grep("_treat$", nm)
J <- length(treat_idx)        # should be 10
K <- length(b_hat)            # should be 20

# 2) build R matrix selecting treat coefficients: R b = (pi_1,1,...,pi_1,J)'
R <- matrix(0, nrow = J, ncol = K)
for (j in 1:J) R[j, treat_idx[j]] <- 1
r0 <- rep(0, J)

# 3) compute quadratic form Q = (R b - r)' (R V R')^{-1} (R b - r)
d <- as.vector(R %*% b_hat - r0)
Q <- as.numeric(t(d) %*% solve(R %*% V_hat %*% t(R)) %*% d)

# 4) F statistic and p-value using F_{J, Jn-K}
F_stat <- Q / J
df1 <- J
n <- 445
df2 <- J*n - K                         # should be 4430
p_F <- 1 - pf(F_stat, df1 = df1, df2 = df2)

# 5) S (Wald) statistic and p-value using Chi-square_J
S_stat <- J * F_stat   # equals Q
p_S <- 1 - pchisq(S_stat, df = J)

c(J=J, K=K, n=n, df2=df2,
  F_stat=F_stat, p_value_F=p_F,
  S_stat=S_stat, p_value_S=p_S)

```

### Script and Output
We test the joint null hypothesis that the coefficients on \texttt{treat} are zero in all $J=10$ equations:
\[
H_0:\ \pi_{1,1}=\pi_{1,2}=\cdots=\pi_{1,10}=0.
\]
Using the companion document's expressions for Procedure 4, we compute the $F$ statistic and the Wald ($S$) statistic.
With $n=445$ observations per equation and $K=2J=20$ parameters in the stacked system, the denominator degrees of freedom are
\[
Jn-K = 10\times 445 - 20 = 4430.
\]
Our manual calculations yield
\[
F = 2.0466 \quad \text{with} \quad p\text{-value} = 0.0254 \ \ \text{using } F_{10,4430},
\]
and equivalently
\[
S = J\cdot F = 20.4656 \quad \text{with} \quad p\text{-value} = 0.0251 \ \ \text{using } \chi^2_{10}.
\]
At the 5\% level, we reject $H_0$, indicating that the OPVs are not jointly balanced across treatment and control.

---

### (\textcolor{blue}{[ \ \ ]} out of 4p) Q2.e: Implement Joint Test Automatically

### Script and Output

```{r q2e-automatic-joint-test, echo=TRUE}
library(car)

# Names of coefficients
names(coef(sur_fit))

# Joint null: all treat coefficients equal zero
# We write one restriction per equation
lh <- linearHypothesis(
  sur_fit,
  c(
    "age_treat = 0",
    "edu_treat = 0",
    "nodegree_treat = 0",
    "black_treat = 0",
    "hisp_treat = 0",
    "married_treat = 0",
    "u74_treat = 0",
    "u75_treat = 0",
    "re74_treat = 0",
    "re75_treat = 0"
  ),
  test = "F"
)

lh

```
```{r}
F_auto <- lh[2, "F"]
S_auto <- 10 * F_auto

c(F_auto = F_auto, S_auto = S_auto)

```


### Commentary
The automatic joint test implemented via \texttt{car::linearHypothesis()} yields
an $F$ statistic of $2.0466$ with a $p$-value of $0.02538$.
These values coincide exactly with those obtained from the manual construction of the
Wald test in Q2.d, as both procedures rely on the same linear restrictions and the same
estimated variance--covariance matrix from the SUR estimator.

---

### (\textcolor{blue}{[ \ \ ]} out of 1p) Q2.f: Decision
At the 5\% significance level, we reject the joint null hypothesis that all coefficients
on \texttt{treat} are equal to zero across the system of equations.
---


## (\textcolor{blue}{[ \ \ ]} out of 3p) Q3: Implement Procedure 5 (Hotelling's T2 Test)

### Script and Output

```{r q3-hotelling, echo=TRUE}
opvs <- c("age","edu","nodegree","black","hisp",
          "married","u74","u75","re74","re75")

X1 <- df[df$treat == 1, opvs]
X0 <- df[df$treat == 0, opvs]

# Use DescTools::HotellingsT2Test()
if (!requireNamespace("DescTools", quietly = TRUE)) install.packages("DescTools")
library(DescTools)

ht <- DescTools::HotellingsT2Test(X1, X0)
ht

# Extract T2 and p-value (in case you want to print neatly)
T2 <- as.numeric(ht$statistic)
p_T2 <- as.numeric(ht$p.value)

c(T2 = T2, p_value = p_T2)

```


### Commentary
We implement Procedure 5 using Hotelling’s two-sample $T^2$ test via
\texttt{DescTools::HotellingsT2Test()} to assess joint balance in the
$J=10$ observed predetermined variables (OPVs).
The null hypothesis is
\[
H_0:\ \mathbb{E}[X \mid D=1] = \mathbb{E}[X \mid D=0],
\]
against the alternative that at least one component differs.

The test yields a Hotelling’s statistic of $T^2 = 2.005$.
Using the finite-sample $F$-approximation with degrees of freedom $(10,434)$,
the associated $p$-value is $0.0314$.
At the 5\% significance level, we therefore reject the null hypothesis of joint balance
in the OPVs.

This result is consistent with the joint SUR-based Wald test in Procedure~4 and
with the treatment-assignment regression test in Procedure~6.
Differences in numerical values across procedures reflect different finite-sample
approximations (chi-square versus $F$), not differences in the underlying hypothesis
being tested.
---

## (\textcolor{blue}{[ \ \ ]} out of 4p) Q4: Implement Procedure 6 (OPV do not predict treatment assignment)

### Script and Output

```{r q4-proc6-lpm, echo=TRUE}
opvs <- c("age","edu","nodegree","black","hisp",
          "married","u74","u75","re74","re75")

lm_fit <- lm(treat ~ age + edu + nodegree + black + hisp +
               married + u74 + u75 + re74 + re75,
             data = df)

summary(lm_fit)$r.squared
summary(lm_fit)$fstatistic   # (value, numdf, dendf)
```
```{r}
R2 <- summary(lm_fit)$r.squared
n  <- nobs(lm_fit)
M  <- length(opvs)  # number of slope parameters (10)

F_manual <- (R2 / M) / ((1 - R2) / (n - (M + 1)))
p_manual <- 1 - pf(F_manual, df1 = M, df2 = n - (M + 1))

c(R2 = R2, n = n, M = M, F_manual = F_manual, p_manual = p_manual)

```

### Commentary
We implement Procedure 6 by regressing the treatment indicator on a constant and the
$J=10$ observed predetermined variables using a linear probability model.
Let $R^2$ denote the coefficient of determination from this regression and let $M=10$
be the number of slope parameters.
Following the companion document, we compute the overall significance test statistic
\[
F=\frac{R^2/M}{(1-R^2)/(n-(M+1))},
\]
and obtain the corresponding $p$-value from an $F_{M,\,n-(M+1)}$ distribution.
Using $n=445$, we obtain $F=2.005$ with a $p$-value of $0.0314$.
We reject the null hypothesis.
---

## (\textcolor{blue}{[ \ \ ]} out of 5p) Q5: Implement Procedures 7 and 8 (control for FWER)
### Script and Output
```{r q5-fwer, echo=TRUE}
# Q5: Procedures 7 (Bonferroni) and 8 (Holm-Bonferroni)
# We use the one-at-a-time p-values for H0,j: pi_{1,j}=0 (treat coefficient = 0) for each OPV.

opvs <- c("age","edu","nodegree","black","hisp","married","u74","u75","re74","re75")

# If you already created ols_fits in Q2.b, you can reuse it.
# Otherwise:
ols_fits <- lapply(opvs, function(v) lm(as.formula(paste0(v, " ~ treat")), data = df))
names(ols_fits) <- opvs

# Extract unadjusted p-values for treat in each equation
p_raw <- sapply(ols_fits, function(m) summary(m)$coefficients["treat","Pr(>|t|)"])

# Procedure 7: Bonferroni adjusted p-values = p_adj_j = min(1, J * p_j)
# (implemented by p.adjust(method="bonferroni"))
p_bonf <- p.adjust(p_raw, method = "bonferroni")

# Procedure 8: Holm-Bonferroni adjusted p-values (implemented by p.adjust(method="holm"))
p_holm <- p.adjust(p_raw, method = "holm")

# Collect results
res_q5 <- data.frame(
  OPV = opvs,
  p_raw = as.numeric(p_raw),
  p_bonf = as.numeric(p_bonf),
  p_holm = as.numeric(p_holm),
  reject_bonf_5pct = (p_bonf <= 0.05),
  reject_holm_5pct = (p_holm <= 0.05)
)

# Show table sorted by raw p-values (helpful for interpretation)
res_q5[order(res_q5$p_raw), ]

```


### Commentary
Q5 controls the family-wise error rate (FWER) when testing balance in the $J=10$ OPVs
using one-at-a-time tests of
$H_{0,j}:\pi_{1,j}=0$ for each OPV $j$.
Following the programming guidance, we implement:

\begin{itemize}
\item \textbf{Procedure 7 (Bonferroni)}, which adjusts p-values as
$p^{(B)}_j=\min\{1,Jp_j\}$; and
\item \textbf{Procedure 8 (Holm--Bonferroni)}, a step-down procedure that is weakly less
conservative than Bonferroni.
\end{itemize}

Both procedures are implemented using \texttt{stats::p.adjust()}.
At the 5\% significance level, only \texttt{nodegree} remains statistically significant
after controlling the FWER under both Bonferroni and Holm--Bonferroni adjustments.
All other OPVs have adjusted p-values well above 0.05.

Therefore, we reject the joint null hypothesis of perfect balance across the OPVs,
but the evidence for imbalance is driven entirely by the \texttt{nodegree} variable.
This result is consistent with the earlier joint balance tests (Procedures 4 and 5)
and the treatment-assignment test (Procedure 6).
---

# (\textcolor{blue}{[ \ \ ]} out of 50p) PART II: Review of OLS for Causal Analysis

## (\textcolor{blue}{[ \ \ ]} out of 3p) Q6: Two ways of obtaining the DM estimator

### Script and Output

```{r q6-fwer, echo=TRUE}

treated  <- read.csv("nswre74_treated.csv")
control  <- read.csv("nswre74_control.csv")
treated$treat <- 1
control$treat <- 0

df <- rbind(treated, control)

df$re74 <- df$re74 / 1000
df$re75 <- df$re75 / 1000

## Keep / check core variables
vars <- c("re78", "treat", "re74", "re75")
stopifnot(all(vars %in% names(df)))

## Optional: quick checks
with(df, table(treat))
summary(df[, vars])

df$re74 <- df$re74 / 1000
df$re75 <- df$re75 / 1000

fit1 <- lm(re78 ~ treat, data = df)
rho_ols <- coef(fit1)[["treat"]]

dm <- with(df, mean(re78[treat == 1]) - mean(re78[treat == 0]))

# optional: “manual OLS” slope via covariance/variance
rho_manual <- with(df, cov(treat, re78) / var(treat))

c(rho_ols = rho_ols, dm = dm, rho_manual = rho_manual)
all.equal(rho_ols, dm)
all.equal(rho_ols, rho_manual)

```

### Commentary

Estimate of spec 1 by OLS, regressing post-intervention earnings on the treatment indicator is found by:
$$
\texttt{re78}_i = \alpha + \rho,\texttt{treat}_i + u_i.
$$
Under the random assignment of the NSW experiment, the OLS estimator of $\rho$ coincides with the difference in mean outcomes between treated and control groups.
To verify this result, we compute:

1. $\hat\rho_{\text{OLS}}$: the OLS slope on $\texttt{treat}_i$;
2. $\widehat{DM} = \bar{\texttt{re78}}*{1}-\bar{\texttt{re78}}*{0}$: the difference in sample average earnings between treated and control;
3. $\hat\rho_{\text{manual}}$: the OLS slope computed manually as $\widehat{\text{Cov}}(\texttt{treat}_i,\texttt{re78}_i)/\widehat{\text{Var}}(\texttt{treat}_i)$ (to be sure)

Results: 
$$
\hat\rho_{\text{OLS}} = 1794.342, \qquad
\widehat{DM} = 1794.342, \qquad
\hat\rho_{\text{manual}} = 1794.342.
$$

As seen above, all quantities are numerically identical. Indeed, the OLS estimator of the treatment coefficient exactly equals the difference in average 1978 earnings between treated and control units. This was checked by the manual computation in $\hat\rho_{\text{manual}}$. The estimated ATE implies that being offered training increases earnings in 1978 by approximately $1,794 on average.


---

## (\textcolor{blue}{[ \ \ ]} out of 4p) Q7: Fully-saturated specification in Nodegree

### Script and Output
```{r q7-fwer, echo=TRUE}
df$degree <- 1 - df$nodegree

fit_fs <- lm(re78 ~ 0 + nodegree + degree + treat:nodegree + treat:degree, data = df)
coef(fit_fs)

b <- coef(fit_fs)

rho1 <- b["nodegree:treat"]   # CATE for nodegree = 1
rho2 <- b["degree:treat"]     # CATE for nodegree = 0

s1 <- mean(df$nodegree == 1)  # share without degree
s0 <- mean(df$nodegree == 0)  # share with degree

ate_hat <- s1 * rho1 + s0 * rho2

c(
  CATE_nodegree1 = rho1,
  CATE_nodegree0 = rho2,
  ATE = ate_hat
)
```

---

## (\textcolor{blue}{[ \ \ ]} out of 2p) Q8: Get $\widehat{ATE}$ in one step

Implementing the $M=2$ version of the shortcut specification, we have:

### Script and Output
```{r q8-fwer, echo=TRUE}
df$re74 <- df$re74 / 1000
df$re75 <- df$re75 / 1000

B2 <- as.integer(df$nodegree == 1)  # nodegree group
B1 <- 1 - B2                        # degree group

N  <- nrow(df)
N2 <- sum(B2)
N1 <- sum(B1)

Z_eps <- df$treat * B2 * (N2 / N)
Z_varpi1 <- df$treat * (B1 - B2 * (N1 / N2))

fit_short <- lm(df$re78 ~ 0 + B1 + B2 + Z_varpi1 + Z_eps)
coef(fit_short)[["Z_eps"]]


```

The coefficient on `Z_eps` is $\hat\epsilon$ which equals $\widehat{ATE}$ by construction.

---

## (\textcolor{blue}{[ \ \ ]} out of 22p) Q9: Implications of estimating a not-fully saturated specification in an OPV that takes $M$ distinct values

  In the fully saturated approach, we have $\hat\rho_m=\bar Y_{1,m}-\bar Y_{0,m}$. Consider instead the shortcut regression
$$
  Y_i = \sum_{m=1}^M \theta_m 1[x_i=a_m]+\rho D_i+u_i.
$$
Partialling out the indicators $1[x_i=a_m]$ yields residualized variables $\tilde Y_i=Y_i-\bar Y_{m(i)}, \tilde D_i=D_i-\bar D_{m(i)}$, hence
$$
  \hat\rho=\frac{\sum_i \tilde D_i\tilde Y_i}{\sum_i \tilde D_i^2}.
$$
Grouping by $m$:
$$
  \hat\rho=\sum_{m=1}^M \hat\omega_m\bigl(\bar Y_{1,m}-\bar Y_{0,m}\bigr),
  \qquad
  \hat\omega_m=\frac{\hat s_m\widehat{Var}(D|x=a_m)}{\sum_{j=1}^M \hat s_j\widehat{Var}(D|x=a_j)},
$$
where $\widehat{Var}(D|x=a_m)=\bar D_m(1-\bar D_m)$.

To investigate when we have $\hat\rho=\widehat{ATE}$, we have that the fully saturated ATE estimator is $\widehat{ATE}=\sum_m \hat s_m\hat\rho_m$, while the shortcut is $\hat\rho=\sum_m \hat\omega_m\hat\rho_m)$. Thus we have $\hat\rho=\widehat{ATE}$ if either:
  
  1. treated shares are identical across $m$ (so $\widehat{Var}(D|m)$ is constant and $\hat\omega_m=\hat s_m)$; or
2. $\hat\rho_m$ is identical across $m$, so any weighting yields the same average.

Proving the consistency of $\hat\rho$, the deck states that regressing $Y_i$ on $(1,D_i,1[x_i=a_1],\dots,1[x_i=a_M])$ yields an OLS coefficient on $D_i$ that is consistent for ATE iff assignment probabilities are independent of $x_i$ or treatment effects are homogeneous in $x_i$ as in the notes. This matches the limit of the weighting representation: the shortcut converges to a variance-weighted average of CATEs, which equals the population-share-weighted ATE only under those conditions.

Showing even split and precision weighting, if $\hat s_m=1/M$ for all $m$, then $\widehat{ATE}=\frac{1}{M}\sum_m \hat\rho_m$, namely equal weight across cells.

Pertaining to the shortcut, we have that $\hat\omega_m\propto Var(D|m)=\bar D_m(1-\bar D_m)$, so it emphasizes cells with more within-cell treated/control balance. Under the usual within-cell homoskedasticity condition, slope variance scales like $\sigma_m^2/SST_{D,m}$, and for binary (D), $SST_{D,m}\propto n_m\bar D_m(1-\bar D_m)$ (Companion-to-NSW-Application: derivation using `SST_D` and $n\bar D(1-\bar D))$. Hence larger $Var(D|m)$ corresponds to more precise within-cell treatment-effect estimation, so the shortcut places relatively more weight on the more precisely estimated CATEs in that sense.

**Takeaway**: Fully saturating in a discrete confounder $x$ averages cell-by-cell treatment effects using the population (or sample) composition. The fixed-effects shortcut that adds $x$ indicators but does not interact them with treatment instead averages the same cell-by-cell effects using weights that depend on how much within-cell variation there is in treatment assignment. This generally changes the estimand unless either assignment rates are constant across cells or treatment effects are constant across cells.

---

## (\textcolor{blue}{[ \ \ ]} out of 14p) Q10: Implement the DM estimator with Regression Adjustment (various specifications)

### (\textcolor{blue}{[ \ \ ]} out of 3p) Q10.a: Estimate Specifications 2, 3 and 4

### (\textcolor{blue}{[ \ \ ]} out of 1p) Q10.a.i: Estimate Specification 2

### Script and Output

```{r q10ai-fwer, echo=TRUE}
df$re74 <- df$re74 / 1000
df$re75 <- df$re75 / 1000

# Spec 2
fit2 <- lm(re78 ~ treat + nodegree + edu, data = df)

# Spec 3 (nodegree + edu + other 8 OPVs; typical NSW OPVs shown)
fit3 <- lm(re78 ~ treat + nodegree + edu + age + black + hisp + married + re74 + re75 + u74 + u75,
           data = df)

# Spec 4: add treat × (age - mean(age))
df$age_c <- df$age - mean(df$age)
fit4 <- lm(re78 ~ treat + nodegree + edu + age + black + hisp + married + re74 + re75 + u74 + u75 +
             treat:age_c,
           data = df)

# ATE estimate + t-test (via lm summary)
summ <- function(fit) summary(fit)$coef["treat", c("Estimate","Std. Error","t value","Pr(>|t|)")]
rbind(Spec2 = summ(fit2), Spec3 = summ(fit3), Spec4 = summ(fit4))

summ(fit2)
```

### Commentary

The table above reports estimates of the ATE of being offered training on 1978 earnings under three regression‐adjustment specifications. Across Specifications 2–4, the estimated ATE is remarkably stable, ranging from approximately \$1,646 to \$1,671. In all cases, the null hypothesis that the ATE is zero is rejected at the 1\% level using the standard OLS t‐test.

Interpretation:
Spec 2 adjusts only for educational attainment (`nodegree`, `edu`). The estimated ATE is positive and statistically significant at the 5% level. This indicates that, even with a minimal set of controls focused on education, the offer of training is associated with an increase in 1978 earnings of roughly $1,646 on average. Because education is a strong predictor of earnings, including it helps account for outcome variation without materially altering the experimental contrast between treated and control units.

---

### (\textcolor{blue}{[ \ \ ]} out of 1p) Q10.a.ii: Estimate Specification 3

### Script and Output
```{r q10aii-fwer, echo=TRUE}
summ(fit3)
```

### Commentary

Spec 3 adds the full set of observed pre-treatment variables to the regression. The estimated ATE remains very close to that from Spec 2 and is again statistically significant at the 1% level. The similarity of the point estimates across Specifications 2 and 3 suggests that additional OPVs beyond education do not meaningfully change the estimated treatment effect, consistent with the plausibility of random assignment. The standard error is also of similar magnitude, indicating modest efficiency gains from the expanded covariate set.

---

### (\textcolor{blue}{[ \ \ ]} out of 1p) Q10.a.iii: Estimate Specification 4

### Script and Output
```{r q10aiii-fwer, echo=TRUE}
summ(fit4)
```

### Commentary

Spec 4 allows for treatment-effect heterogeneity by age through an interaction between treatment and centered age. The estimated average effect, evaluated at the sample mean age, is again very close to those obtained under Specifications 2 and 3 and remains statistically significant at conventional levels. This indicates that allowing for age-related heterogeneity does not materially alter the estimated average impact of the training offer, reinforcing the robustness of the ATE estimate across alternative regression-adjustment specifications.

Across all three specifications, the estimated ATE is stable—approximately \$1,650–\$1,670—and statistically significant. This consistency suggests that regression adjustment using balanced OPVs primarily serves to refine precision rather than to change the estimated treatment effect.

---

### (\textcolor{blue}{[ \ \ ]} out of 5p) Q10.b: Reasons to include OPVs when they are balanced


Even if OPVs are balanced between treated and control groups, including them as regression covariates can be useful for at least two reasons:

1. If OPVs explain variation in $\texttt{re78}$, then controlling for them can reduce the residual variance and thereby reduce the standard error of $\hat\rho$, yielding higher precision and tighter inference for the ATE. This is relevant even under randomized assignment because balance affects bias, not necessarily variance.

2. Even in experiments, exact balance typically holds only in expectation. In a realized finite sample, adjusting for prognostic covariates can stabilize estimates and improve finite-sample efficiency.

Moving from Spec 2 to Spec 3 adds additional OPVs. If these added OPVs are predictive of $\texttt{re78}$, then we would expect the standard error of the $\texttt{treat}$ coefficient to decrease or , while the point estimate may or may not change depending on finite-sample correlations.

---

### (\textcolor{blue}{[ \ \ ]} out of 1p) Q10.c:  Is it problematic to regression-adjust for OPVs that are lagged outcomes?


Using lagged outcomes (as is the case for $\texttt{re74}, \texttt{re75})$ as regression covariates is not problematic so long as they are measured prior to treatment. In that case they are OPVs (pre-treatment variables) and can help improve precision because they tend to be strong predictors of future earnings. The main concern would be conditioning on variables affected by treatment (post-treatment variables), but $\texttt{re74}$ and $\texttt{re75}$ are pre-intervention in the NSW setting.

---

### (\textcolor{blue}{[ \ \ ]} out of 5p) Q10.d:  Interactions of OPV with Treatment Indicator and Two Hypothesis Testing Problems

### Script and Output

```{r q10aiiii-fwer, echo=TRUE}
library(car)

# (i) Test H0: ATE = 0 in Spec 4 (coefficient on treat)
car::linearHypothesis(fit4, "treat = 0")

# (ii) Test H0: effect does not vary by age (interaction term equals 0)
car::linearHypothesis(fit4, "treat:age_c = 0")
```

### Commentary

Interactions between OPVs and the treatment indicator allow the conditional average treatment effect to vary with observed characteristics (treatment effect heterogeneity). In Spec 4, the interaction with centered age explicitly models heterogeneity by age.

In each hypothesis test, we have 

1. (H_0:) ATE is zero corresponds to testing $\rho=0$, so `treat = 0`.
2. (H_0:) no age heterogeneity corresponds to testing $\gamma=0$, so `treat:age_c = 0`.

Each hypothesis is tested one-at-a-time using `car::linearHypothesis()` as instructed in the guidance.

---


## (\textcolor{blue}{[ \ \ ]} out of 5p) Q11: Mechanisms for NSW intervention to impact post-intervention earnings

A plausible mechanism is that being offered the NSW program increases earnings in 1978 by increasing employment and job-specific human capital: the offer provides access to subsidized employment and training, which can raise labor market experience and skills, improving productivity and employability, and thus increasing post-intervention earnings measured in 1978.
